{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstall the package from local source to get the latest fixes\n",
    "# %pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-18T21:14:23.615315Z",
     "iopub.status.busy": "2025-07-18T21:14:23.614871Z",
     "iopub.status.idle": "2025-07-18T21:18:31.302090Z",
     "shell.execute_reply": "2025-07-18T21:18:31.301331Z",
     "shell.execute_reply.started": "2025-07-18T21:14:23.615277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!pip -q install locisimiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T21:18:37.715908Z",
     "iopub.status.busy": "2025-07-18T21:18:37.713451Z",
     "iopub.status.idle": "2025-07-18T21:18:46.840802Z",
     "shell.execute_reply": "2025-07-18T21:18:46.837817Z",
     "shell.execute_reply.started": "2025-07-18T21:18:37.715835Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianschelb/.pyenv/versions/locisimiles-test/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from locisimiles.evaluator import IntertextEvaluator\n",
    "from locisimiles.pipeline import (\n",
    "    ClassificationPipeline,\n",
    "    ClassificationPipelineWithCandidategeneration,\n",
    "    pretty_print,\n",
    ")\n",
    "from locisimiles.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded query and source documents:\n",
      "Query Document: Document('hieronymus_samples.csv', segments=11, author='Hieronymus', meta={})\n",
      "Source Document: Document('vergil_samples.csv', segments=10, author='Vergil', meta={})\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load example query and source documents\n",
    "query_doc = Document(\"./hieronymus_samples.csv\", author=\"Hieronymus\")\n",
    "source_doc = Document(\"./vergil_samples.csv\", author=\"Vergil\")\n",
    "\n",
    "print(\"Loaded query and source documents:\")\n",
    "print(f\"Query Document: {query_doc}\")\n",
    "print(f\"Source Document: {source_doc}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Stage Pipeline (Retrieval + Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding query segments: 100%|██████████| 11/11 [00:00<00:00, 305545.32it/s]\n",
      "Embedding source segments: 100%|██████████| 10/10 [00:00<00:00, 287281.10it/s]\n",
      "Check candidates: 100%|██████████| 11/11 [00:04<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the two-stage pipeline run:\n",
      "\n",
      "▶ Query segment 'hier. adv. iovin. 1.1':\n",
      "  verg. aen. 10.636          sim=+0.661  P(pos)=0.974\n",
      "  verg. ecl. 8.62            sim=+0.610  P(pos)=0.000\n",
      "  verg. ecl. 3.26            sim=+0.609  P(pos)=0.000\n",
      "  verg. aen. 10.875          sim=+0.599  P(pos)=0.000\n",
      "  verg. georg. 2.475         sim=+0.598  P(pos)=0.000\n",
      "  verg. georg. 1.197         sim=+0.545  P(pos)=0.000\n",
      "  verg. ecl. 3.49            sim=+0.485  P(pos)=0.000\n",
      "  verg. aen. 1.177           sim=+0.484  P(pos)=0.000\n",
      "  verg. aen. 4.172           sim=+0.437  P(pos)=0.000\n",
      "  verg. aen. 11.508          sim=+0.407  P(pos)=0.000\n",
      "\n",
      "▶ Query segment 'hier. adv. iovin. 1.41':\n",
      "  verg. aen. 11.508          sim=+0.883  P(pos)=0.988\n",
      "  verg. ecl. 3.49            sim=+0.559  P(pos)=0.000\n",
      "  verg. aen. 4.172           sim=+0.539  P(pos)=0.000\n",
      "  verg. ecl. 8.62            sim=+0.503  P(pos)=0.000\n",
      "  verg. aen. 1.177           sim=+0.501  P(pos)=0.000\n",
      "  verg. georg. 2.475         sim=+0.483  P(pos)=0.000\n",
      "  verg. aen. 10.636          sim=+0.476  P(pos)=0.000\n",
      "  verg. ecl. 3.26            sim=+0.470  P(pos)=0.000\n",
      "  verg. aen. 10.875          sim=+0.469  P(pos)=0.000\n",
      "  verg. georg. 1.197         sim=+0.402  P(pos)=0.000\n",
      "\n",
      "▶ Query segment 'hier. adv. iovin. 2.36':\n",
      "  verg. aen. 4.172           sim=+0.810  P(pos)=0.997\n",
      "  verg. aen. 1.177           sim=+0.548  P(pos)=0.000\n",
      "  verg. ecl. 3.49            sim=+0.505  P(pos)=0.001\n",
      "  verg. ecl. 8.62            sim=+0.496  P(pos)=0.000\n",
      "  verg. georg. 1.197         sim=+0.482  P(pos)=0.000\n",
      "  verg. ecl. 3.26            sim=+0.466  P(pos)=0.000\n",
      "  verg. aen. 10.636          sim=+0.451  P(pos)=0.000\n",
      "  verg. aen. 11.508          sim=+0.445  P(pos)=0.000\n",
      "  verg. georg. 2.475         sim=+0.432  P(pos)=0.000\n",
      "  verg. aen. 10.875          sim=+0.414  P(pos)=0.000\n",
      "\n",
      "▶ Query segment 'hier. adv. pelag. 1.23':\n",
      "  verg. ecl. 8.62            sim=+0.735  P(pos)=0.981\n",
      "  verg. georg. 1.197         sim=+0.535  P(pos)=0.000\n",
      "  verg. georg. 2.475         sim=+0.473  P(pos)=0.000\n",
      "  verg. aen. 1.177           sim=+0.469  P(pos)=0.000\n",
      "  verg. ecl. 3.26            sim=+0.417  P(pos)=0.000\n",
      "  verg. ecl. 3.49            sim=+0.416  P(pos)=0.000\n",
      "  verg. aen. 10.875          sim=+0.401  P(pos)=0.000\n",
      "  verg. aen. 4.172           sim=+0.389  P(pos)=0.000\n",
      "  verg. aen. 10.636          sim=+0.366  P(pos)=0.000\n",
      "  verg. aen. 11.508          sim=+0.364  P(pos)=0.000\n",
      "\n",
      "▶ Query segment 'hier. adv. pelag. 3.11':\n",
      "  verg. ecl. 3.49            sim=+0.867  P(pos)=0.995\n",
      "  verg. ecl. 8.62            sim=+0.540  P(pos)=0.000\n",
      "  verg. georg. 2.475         sim=+0.537  P(pos)=0.000\n",
      "  verg. ecl. 3.26            sim=+0.526  P(pos)=0.000\n",
      "  verg. aen. 10.875          sim=+0.500  P(pos)=0.000\n",
      "  verg. aen. 10.636          sim=+0.482  P(pos)=0.000\n",
      "  verg. aen. 4.172           sim=+0.474  P(pos)=0.000\n",
      "  verg. georg. 1.197         sim=+0.465  P(pos)=0.000\n",
      "  verg. aen. 1.177           sim=+0.459  P(pos)=0.000\n",
      "  verg. aen. 11.508          sim=+0.437  P(pos)=0.000\n",
      "\n",
      "▶ Query segment 'hier. adv. pelag. 3.4':\n",
      "  verg. georg. 1.197         sim=+0.808  P(pos)=0.460\n",
      "  verg. ecl. 8.62            sim=+0.641  P(pos)=0.001\n",
      "  verg. georg. 2.475         sim=+0.611  P(pos)=0.001\n",
      "  verg. aen. 1.177           sim=+0.572  P(pos)=0.003\n",
      "  verg. ecl. 3.49            sim=+0.512  P(pos)=0.001\n",
      "  verg. aen. 10.636          sim=+0.497  P(pos)=0.001\n",
      "  verg. ecl. 3.26            sim=+0.468  P(pos)=0.001\n",
      "  verg. aen. 10.875          sim=+0.455  P(pos)=0.001\n",
      "  verg. aen. 4.172           sim=+0.443  P(pos)=0.002\n",
      "  verg. aen. 11.508          sim=+0.350  P(pos)=0.001\n",
      "\n",
      "▶ Query segment 'hier. adv. rufin. 1.17':\n",
      "  verg. ecl. 3.26            sim=+0.957  P(pos)=0.997\n",
      "  verg. aen. 1.177           sim=+0.653  P(pos)=0.000\n",
      "  verg. georg. 1.197         sim=+0.601  P(pos)=0.000\n",
      "  verg. georg. 2.475         sim=+0.560  P(pos)=0.000\n",
      "  verg. ecl. 8.62            sim=+0.531  P(pos)=0.000\n",
      "  verg. ecl. 3.49            sim=+0.510  P(pos)=0.000\n",
      "  verg. aen. 10.636          sim=+0.509  P(pos)=0.000\n",
      "  verg. aen. 4.172           sim=+0.475  P(pos)=0.000\n",
      "  verg. aen. 10.875          sim=+0.458  P(pos)=0.000\n",
      "  verg. aen. 11.508          sim=+0.414  P(pos)=0.000\n",
      "\n",
      "▶ Query segment 'hier. adv. rufin. 1.5':\n",
      "  verg. aen. 10.875          sim=+0.762  P(pos)=0.997\n",
      "  verg. ecl. 8.62            sim=+0.580  P(pos)=0.000\n",
      "  verg. aen. 1.177           sim=+0.545  P(pos)=0.000\n",
      "  verg. georg. 2.475         sim=+0.521  P(pos)=0.001\n",
      "  verg. georg. 1.197         sim=+0.518  P(pos)=0.000\n",
      "  verg. aen. 10.636          sim=+0.514  P(pos)=0.000\n",
      "  verg. aen. 4.172           sim=+0.502  P(pos)=0.000\n",
      "  verg. ecl. 3.49            sim=+0.491  P(pos)=0.000\n",
      "  verg. aen. 11.508          sim=+0.465  P(pos)=0.000\n",
      "  verg. ecl. 3.26            sim=+0.463  P(pos)=0.000\n",
      "\n",
      "▶ Query segment 'hier. adv. rufin. 1.6':\n",
      "  verg. aen. 1.177           sim=+0.667  P(pos)=0.993\n",
      "  verg. ecl. 3.26            sim=+0.608  P(pos)=0.000\n",
      "  verg. ecl. 8.62            sim=+0.574  P(pos)=0.000\n",
      "  verg. georg. 2.475         sim=+0.563  P(pos)=0.000\n",
      "  verg. georg. 1.197         sim=+0.553  P(pos)=0.000\n",
      "  verg. aen. 4.172           sim=+0.521  P(pos)=0.000\n",
      "  verg. aen. 10.636          sim=+0.508  P(pos)=0.000\n",
      "  verg. ecl. 3.49            sim=+0.497  P(pos)=0.000\n",
      "  verg. aen. 10.875          sim=+0.476  P(pos)=0.000\n",
      "  verg. aen. 11.508          sim=+0.467  P(pos)=0.000\n",
      "\n",
      "▶ Query segment 'hier. adv. rufin. 3.28':\n",
      "  verg. georg. 2.475         sim=+0.825  P(pos)=0.994\n",
      "  verg. georg. 1.197         sim=+0.670  P(pos)=0.000\n",
      "  verg. aen. 10.636          sim=+0.647  P(pos)=0.000\n",
      "  verg. aen. 1.177           sim=+0.626  P(pos)=0.000\n",
      "  verg. ecl. 3.26            sim=+0.554  P(pos)=0.000\n",
      "  verg. ecl. 8.62            sim=+0.540  P(pos)=0.000\n",
      "  verg. aen. 10.875          sim=+0.507  P(pos)=0.000\n",
      "  verg. ecl. 3.49            sim=+0.496  P(pos)=0.000\n",
      "  verg. aen. 4.172           sim=+0.436  P(pos)=0.000\n",
      "  verg. aen. 11.508          sim=+0.373  P(pos)=0.000\n",
      "\n",
      "▶ Query segment 'hier. adv. rufin. 3.29':\n",
      "  verg. georg. 1.197         sim=+0.585  P(pos)=0.001\n",
      "  verg. georg. 2.475         sim=+0.560  P(pos)=0.002\n",
      "  verg. ecl. 8.62            sim=+0.559  P(pos)=0.004\n",
      "  verg. ecl. 3.26            sim=+0.520  P(pos)=0.001\n",
      "  verg. aen. 1.177           sim=+0.519  P(pos)=0.001\n",
      "  verg. aen. 10.636          sim=+0.507  P(pos)=0.002\n",
      "  verg. aen. 4.172           sim=+0.495  P(pos)=0.001\n",
      "  verg. aen. 10.875          sim=+0.464  P(pos)=0.001\n",
      "  verg. ecl. 3.49            sim=+0.369  P(pos)=0.001\n",
      "  verg. aen. 11.508          sim=+0.365  P(pos)=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the pipeline with pre-trained models\n",
    "pipeline_two_stage = ClassificationPipelineWithCandidategeneration(\n",
    "    classification_name=\"julian-schelb/PhilBerta-class-latin-intertext-v1\",\n",
    "    embedding_model_name=\"julian-schelb/SPhilBerta-emb-lat-intertext-v1\",\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "# Run the pipeline with the query and source documents\n",
    "results_two_stage = pipeline_two_stage.run(\n",
    "    query=query_doc,    # Query document\n",
    "    source=source_doc,  # Source document\n",
    "    top_k=10             # Number of top similar candidates to classify\n",
    ")\n",
    "print(\"Results of the two-stage pipeline run:\")\n",
    "pretty_print(results_two_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding query segments: 100%|██████████| 11/11 [00:00<00:00, 322638.77it/s]\n",
      "Embedding source segments: 100%|██████████| 10/10 [00:00<00:00, 384798.53it/s]\n",
      "Check candidates: 100%|██████████| 11/11 [00:03<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IntertextEvaluator] Auto-threshold enabled: best smr at threshold=0.10\n",
      "Single sentence:\n",
      " {'query_id': 'hier. adv. iovin. 1.41', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0, 'errors': 0, 'tp': 1, 'fp': 0, 'fn': 0, 'tn': 9, 'fpr': 0.0, 'fnr': 0.0, 'smr': 0.0}\n",
      "\n",
      "Per-sentence head:\n",
      "                  query_id  precision  recall   f1  accuracy  errors  tp  fp  \\\n",
      "0   hier. adv. iovin. 1.1        1.0     1.0  1.0       1.0       0   1   0   \n",
      "1  hier. adv. iovin. 1.41        1.0     1.0  1.0       1.0       0   1   0   \n",
      "2  hier. adv. iovin. 2.36        1.0     1.0  1.0       1.0       0   1   0   \n",
      "3  hier. adv. pelag. 1.23        1.0     1.0  1.0       1.0       0   1   0   \n",
      "4  hier. adv. pelag. 3.11        1.0     1.0  1.0       1.0       0   1   0   \n",
      "5   hier. adv. pelag. 3.4        1.0     1.0  1.0       1.0       0   1   0   \n",
      "6  hier. adv. rufin. 1.17        1.0     1.0  1.0       1.0       0   1   0   \n",
      "7   hier. adv. rufin. 1.5        1.0     1.0  1.0       1.0       0   1   0   \n",
      "8   hier. adv. rufin. 1.6        1.0     1.0  1.0       1.0       0   1   0   \n",
      "9  hier. adv. rufin. 3.28        1.0     1.0  1.0       1.0       0   1   0   \n",
      "\n",
      "   fn  tn  fpr  fnr  smr  \n",
      "0   0   9  0.0  0.0  0.0  \n",
      "1   0   9  0.0  0.0  0.0  \n",
      "2   0   9  0.0  0.0  0.0  \n",
      "3   0   9  0.0  0.0  0.0  \n",
      "4   0   9  0.0  0.0  0.0  \n",
      "5   0   9  0.0  0.0  0.0  \n",
      "6   0   9  0.0  0.0  0.0  \n",
      "7   0   9  0.0  0.0  0.0  \n",
      "8   0   9  0.0  0.0  0.0  \n",
      "9   0   9  0.0  0.0  0.0  \n",
      "\n",
      "Macro scores:\n",
      "    precision    recall        f1  accuracy  fpr  fnr  smr  tp  fp  fn   tn\n",
      "0   0.909091  0.909091  0.909091       1.0  0.0  0.0  0.0  10   0   0  100\n",
      "\n",
      "Micro scores:\n",
      "    precision  recall   f1  accuracy  fpr  fnr  smr  tp  fp  fn   tn\n",
      "0        1.0     1.0  1.0       1.0  0.0  0.0  0.0  10   0   0  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = IntertextEvaluator(\n",
    "    query_doc=query_doc,\n",
    "    source_doc=source_doc,\n",
    "    ground_truth_csv=\"./ground_truth.csv\",\n",
    "    pipeline=pipeline_two_stage,\n",
    "    top_k=10,\n",
    "    threshold=\"auto\",\n",
    "    auto_threshold_metric=\"smr\",\n",
    ")\n",
    "\n",
    "print(\"Single sentence:\\n\", evaluator.evaluate_single_query(\"hier. adv. iovin. 1.41\"))\n",
    "print(\"\\nPer-sentence head:\\n\", evaluator.evaluate_all_queries().head(10))\n",
    "print(\"\\nMacro scores:\\n\", evaluator.evaluate(average=\"macro\"))\n",
    "print(\"\\nMicro scores:\\n\", evaluator.evaluate(average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Optimal Probability Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.1\n",
      "Best SMR score: 0.0000\n",
      "\n",
      "All metrics at best threshold:\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  accuracy: 1.0000\n",
      "  fpr: 0.0000\n",
      "  fnr: 0.0000\n",
      "  smr: 0.0000\n",
      "  tp: 10.0000\n",
      "  fp: 0.0000\n",
      "  fn: 0.0000\n",
      "  tn: 100.0000\n",
      "\n",
      "\n",
      "Metrics across all thresholds:\n",
      " threshold  precision  recall       f1  accuracy  fpr      fnr      smr   tp  fp  fn    tn\n",
      "       0.1        1.0     1.0 1.000000  1.000000  0.0 0.000000 0.000000 10.0 0.0 0.0 100.0\n",
      "       0.2        1.0     1.0 1.000000  1.000000  0.0 0.000000 0.000000 10.0 0.0 0.0 100.0\n",
      "       0.3        1.0     1.0 1.000000  1.000000  0.0 0.000000 0.000000 10.0 0.0 0.0 100.0\n",
      "       0.4        1.0     1.0 1.000000  1.000000  0.0 0.000000 0.000000 10.0 0.0 0.0 100.0\n",
      "       0.5        1.0     0.9 0.947368  0.990909  0.0 0.009091 0.009091  9.0 0.0 1.0 100.0\n",
      "       0.6        1.0     0.9 0.947368  0.990909  0.0 0.009091 0.009091  9.0 0.0 1.0 100.0\n",
      "       0.7        1.0     0.9 0.947368  0.990909  0.0 0.009091 0.009091  9.0 0.0 1.0 100.0\n",
      "       0.8        1.0     0.9 0.947368  0.990909  0.0 0.009091 0.009091  9.0 0.0 1.0 100.0\n",
      "       0.9        1.0     0.9 0.947368  0.990909  0.0 0.009091 0.009091  9.0 0.0 1.0 100.0\n"
     ]
    }
   ],
   "source": [
    "# Find the optimal threshold that maximizes F1 score\n",
    "best_result, all_thresholds_df = evaluator.find_best_threshold(\n",
    "    metric=\"smr\",           # Optimize for SMR (can also use 'f1', 'precision', 'recall', 'accuracy', 'fpr', 'fnr')\n",
    "    average=\"micro\",       # Use micro-averaging\n",
    ")\n",
    "\n",
    "print(f\"Best threshold: {best_result['best_threshold']}\")\n",
    "print(f\"Best SMR score: {best_result['best_smr']:.4f}\")\n",
    "print(f\"\\nAll metrics at best threshold:\")\n",
    "for k, v in best_result.items():\n",
    "    if k not in ['best_threshold', 'best_smr']:\n",
    "        print(f\"  {k}: {v:.4f}\" if isinstance(v, float) else f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\n\\nMetrics across all thresholds:\")\n",
    "print(all_thresholds_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Metrics for Different Top-K Values\n",
    "\n",
    "Evaluate metrics (including TP, FP, FN, TN) for different `k` values without re-running predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== k = 1 ===\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1:        1.0000\n",
      "  TP: 10.0, FP: 0.0, FN: 0.0, TN: 100.0\n",
      "\n",
      "=== k = 2 ===\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1:        1.0000\n",
      "  TP: 10.0, FP: 0.0, FN: 0.0, TN: 100.0\n",
      "\n",
      "=== k = 3 ===\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1:        1.0000\n",
      "  TP: 10.0, FP: 0.0, FN: 0.0, TN: 100.0\n",
      "\n",
      "=== k = 5 ===\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1:        1.0000\n",
      "  TP: 10.0, FP: 0.0, FN: 0.0, TN: 100.0\n",
      "\n",
      "=== k = 10 ===\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1:        1.0000\n",
      "  TP: 10.0, FP: 0.0, FN: 0.0, TN: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics for different k values (number of candidates to classify)\n",
    "# This uses the existing predictions - no re-running required!\n",
    "k_results = evaluator.evaluate_k_values(\n",
    "    k_values=[1, 2, 3, 5, 10],  # k values to evaluate (must be <= original top_k)\n",
    "    average=\"micro\",            # Use micro-averaging\n",
    ")\n",
    "\n",
    "# Print results for each k\n",
    "for k, metrics in k_results.items():\n",
    "    print(f\"\\n=== k = {k} ===\")\n",
    "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1:        {metrics['f1']:.4f}\")\n",
    "    print(f\"  TP: {metrics['tp']}, FP: {metrics['fp']}, FN: {metrics['fn']}, TN: {metrics['tn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification-Only Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying pairs: 100%|██████████| 11/11 [00:03<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the classification-only pipeline\n",
    "pipeline_clf = ClassificationPipeline(\n",
    "    classification_name=\"julian-schelb/PhilBerta-class-latin-intertext-v1\",\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "# Run the pipeline - classifies all pairs\n",
    "results_clf = pipeline_clf.run(\n",
    "    query=query_doc,\n",
    "    source=source_doc,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered results (P(positive) > 0.7):\n",
      "\n",
      "▶ Query segment 'hier. adv. iovin. 1.1':\n",
      "  verg. aen. 10.636          P(pos)=0.974\n",
      "\n",
      "▶ Query segment 'hier. adv. iovin. 1.41':\n",
      "  verg. aen. 11.508          P(pos)=0.988\n",
      "\n",
      "▶ Query segment 'hier. adv. iovin. 2.36':\n",
      "  verg. aen. 4.172           P(pos)=0.997\n",
      "\n",
      "▶ Query segment 'hier. adv. pelag. 1.23':\n",
      "  verg. ecl. 8.62            P(pos)=0.981\n",
      "\n",
      "▶ Query segment 'hier. adv. pelag. 3.11':\n",
      "  verg. ecl. 3.49            P(pos)=0.995\n",
      "\n",
      "▶ Query segment 'hier. adv. rufin. 1.17':\n",
      "  verg. ecl. 3.26            P(pos)=0.997\n",
      "\n",
      "▶ Query segment 'hier. adv. rufin. 1.5':\n",
      "  verg. aen. 10.875          P(pos)=0.997\n",
      "\n",
      "▶ Query segment 'hier. adv. rufin. 1.6':\n",
      "  verg. aen. 1.177           P(pos)=0.993\n",
      "\n",
      "▶ Query segment 'hier. adv. rufin. 3.28':\n",
      "  verg. georg. 2.475         P(pos)=0.994\n"
     ]
    }
   ],
   "source": [
    "# Filter and display high-probability results\n",
    "threshold = 0.7\n",
    "print(f\"Filtered results (P(positive) > {threshold}):\")\n",
    "for query_id, pairs in results_clf.items():\n",
    "    high_prob_pairs = [(seg, sim, prob) for seg, sim, prob in pairs if prob > threshold]\n",
    "    if high_prob_pairs:\n",
    "        print(f\"\\n▶ Query segment {query_id!r}:\")\n",
    "        for src_seg, sim, ppos in high_prob_pairs:\n",
    "            print(f\"  {src_seg.id:<25}  P(pos)={ppos:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying pairs: 100%|██████████| 11/11 [00:04<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single sentence:\n",
      " {'query_id': 'hier. adv. iovin. 1.41', 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0, 'errors': 0, 'tp': 1, 'fp': 0, 'fn': 0, 'tn': 9, 'fpr': 0.0, 'fnr': 0.0, 'smr': 0.0}\n",
      "\n",
      "Per-sentence head:\n",
      "                  query_id  precision  recall   f1  accuracy  errors  tp  fp  \\\n",
      "0   hier. adv. iovin. 1.1        1.0     1.0  1.0       1.0       0   1   0   \n",
      "1  hier. adv. iovin. 1.41        1.0     1.0  1.0       1.0       0   1   0   \n",
      "2  hier. adv. iovin. 2.36        1.0     1.0  1.0       1.0       0   1   0   \n",
      "3  hier. adv. pelag. 1.23        1.0     1.0  1.0       1.0       0   1   0   \n",
      "4  hier. adv. pelag. 3.11        1.0     1.0  1.0       1.0       0   1   0   \n",
      "5   hier. adv. pelag. 3.4        0.0     0.0  0.0       0.9       1   0   0   \n",
      "6  hier. adv. rufin. 1.17        1.0     1.0  1.0       1.0       0   1   0   \n",
      "7   hier. adv. rufin. 1.5        1.0     1.0  1.0       1.0       0   1   0   \n",
      "8   hier. adv. rufin. 1.6        1.0     1.0  1.0       1.0       0   1   0   \n",
      "9  hier. adv. rufin. 3.28        1.0     1.0  1.0       1.0       0   1   0   \n",
      "\n",
      "   fn  tn  fpr  fnr  smr  \n",
      "0   0   9  0.0  0.0  0.0  \n",
      "1   0   9  0.0  0.0  0.0  \n",
      "2   0   9  0.0  0.0  0.0  \n",
      "3   0   9  0.0  0.0  0.0  \n",
      "4   0   9  0.0  0.0  0.0  \n",
      "5   1   9  0.0  0.1  0.1  \n",
      "6   0   9  0.0  0.0  0.0  \n",
      "7   0   9  0.0  0.0  0.0  \n",
      "8   0   9  0.0  0.0  0.0  \n",
      "9   0   9  0.0  0.0  0.0  \n",
      "\n",
      "Macro scores:\n",
      "    precision    recall        f1  accuracy  fpr       fnr       smr  tp  fp  \\\n",
      "0   0.818182  0.818182  0.818182  0.990909  0.0  0.009091  0.009091   9   0   \n",
      "\n",
      "   fn   tn  \n",
      "0   1  100  \n",
      "\n",
      "Micro scores:\n",
      "    precision  recall        f1  accuracy  fpr       fnr       smr  tp  fp  fn  \\\n",
      "0        1.0     0.9  0.947368  0.990909  0.0  0.009091  0.009091   9   0   1   \n",
      "\n",
      "    tn  \n",
      "0  100  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator_clf = IntertextEvaluator(\n",
    "    query_doc=query_doc,\n",
    "    source_doc=source_doc,\n",
    "    ground_truth_csv=\"./ground_truth.csv\",\n",
    "    pipeline=pipeline_clf,\n",
    "    top_k=len(source_doc),  # All pairs\n",
    "    threshold=0.5,\n",
    ")\n",
    "\n",
    "print(\"Single sentence:\\n\", evaluator_clf.evaluate_single_query(\"hier. adv. iovin. 1.41\"))\n",
    "print(\"\\nPer-sentence head:\\n\", evaluator_clf.evaluate_all_queries().head(10))\n",
    "print(\"\\nMacro scores:\\n\", evaluator_clf.evaluate(average=\"macro\"))\n",
    "print(\"\\nMicro scores:\\n\", evaluator_clf.evaluate(average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Input Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Text (with special tokens):\n",
      "<s>Furiosas Apollinis uates legimus; et illud Uirgilianum: Dat sine mente sonum.</s></s>tum dea nube caua tenuem sine uiribus umbram in faciem Aeneae uisu mirabile monstrum Dardaniis ornat telis clipeumque iubasque diuini assimulat capitis, dat inania uerba, dat sine mente sonum gressusque effingit euntis, morte obita qualis fama est uolitare figuras aut quae sopitos deludunt somnia sensus.</s>\n",
      "\n",
      "Input IDs (first 20): [0, 48157, 2035, 346, 47074, 489, 1604, 16836, 31, 361, 2000, 1931, 410, 75, 588, 4186, 30, 49974, 1747, 6664, 30821, 18, 2, 2, 746, 30897, 29120, 1808, 2338, 24795, 324, 1747, 43883, 31334, 306, 8298, 16723, 381, 12147, 89, 33370, 53290, 28818, 304, 1563, 46427, 33064, 42918, 1995, 6164, 8195, 3576, 1721, 1338, 345, 24206, 13375, 16, 8358, 47435, 21042, 16, 8358, 1747, 6664, 30821, 27783, 7816, 1471, 43780, 26124, 282, 16, 5795, 765, 1174, 10403, 10160, 427, 5805, 14004, 35587, 610, 691, 16603, 7009, 1872, 454, 433, 37650, 5964, 18, 2]\n",
      "Total tokens: 93\n"
     ]
    }
   ],
   "source": [
    "# Get the first query and candidate pair\n",
    "first_query_id = list(query_doc.ids())[0]\n",
    "first_query_text = query_doc.get_text(first_query_id)\n",
    "first_candidate_text = source_doc.get_text(list(source_doc.ids())[0])\n",
    "\n",
    "# Debug the encoding\n",
    "debug_info = pipeline_clf.debug_input_sequence(first_query_text, first_candidate_text)\n",
    "\n",
    "print(f\"\\nInput Text (with special tokens):\")\n",
    "print(debug_info['input_text'])\n",
    "print(f\"\\nInput IDs (first 20): {debug_info['input_ids']}\")\n",
    "print(f\"Total tokens: {len(debug_info['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7897057,
     "sourceId": 12511467,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "locisimiles-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
